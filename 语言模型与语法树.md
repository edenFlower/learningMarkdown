# 语言模型与语法树
## week 1 Syntax Tree & Probability language model
Rule Based Syntax Tree(语法树)
Probaility Based: Language Model
- Language Model: The probability of a sentence.
N-gram Model 发生的概率，条件概率模型
<br/>
- __1-gram(Unigram)__
<br/>
$p({{w}_{i}})=\frac{C({{w}_{i}})}{\sum{\forall kC({{w}_{k}})}}=\frac{C({{w}_{i}})}{N}$
<br/> 
- __1-gram(Unigram)__<br/> 
$p({{w}_{i+1}}|{{w}_{i}})=\frac{C({{w}_{i}},{{w}_{i+1}})}{\sum{\forall kC({{w}_{i,}}{{w}_{k}})}}=\frac{C({{w}_{i}},{{w}_{i+1}})}{C({{w}_{i}})}$ 
<br/>
根据模型处理数据

## week 2 Search Algorithm

### Search Mathods
1. Breadth-first search
2. Depth-first search
3. Optimal search

### Machine learning
1. introduction
2. Optimization(Gradient descent)
4. Linear regression

<font color="#dd0000">Two types of ML problems</font><br />
1. Regression: Learning a function to fit the data
2. classification: learning a hyperplane that can seperate data of different categories.

## week 3 Dynamic Programming & Edit Distance
## week 4 Natural Language Processing(key words Extraction & Topic Model)
## week 5 Machine learning 1
## week 6 Machine learning 2
## week 7 Machine learning 3
## week 8 Deep Learning
## week 9 Word2Vec
## week 10 CNN
## week 11 RNN
## week 12 Transformer & BERT (Large-scale Pretraining Model)
## week 13 Conversational Agent
## week 14 Recent Development of Deep Learning